{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:46:39.417658Z",
     "iopub.status.busy": "2025-07-02T06:46:39.417451Z",
     "iopub.status.idle": "2025-07-02T06:47:58.599444Z",
     "shell.execute_reply": "2025-07-02T06:47:58.598555Z",
     "shell.execute_reply.started": "2025-07-02T06:46:39.417640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install adjustText\n",
    "!pip install torchmetrics[image]\n",
    "!pip install pytorch-msssim torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:48:20.388487Z",
     "iopub.status.busy": "2025-07-02T06:48:20.387906Z",
     "iopub.status.idle": "2025-07-02T06:48:20.394403Z",
     "shell.execute_reply": "2025-07-02T06:48:20.393656Z",
     "shell.execute_reply.started": "2025-07-02T06:48:20.388461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from torchvision.models import inception_v3\n",
    "\n",
    "from pytorch_msssim import ssim as ssim_loss\n",
    "\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance as FID\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity as LPIPS\n",
    "from torchmetrics.functional import peak_signal_noise_ratio as psnr_fn\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim_fn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:48:20.588560Z",
     "iopub.status.busy": "2025-07-02T06:48:20.588217Z",
     "iopub.status.idle": "2025-07-02T06:48:21.162227Z",
     "shell.execute_reply": "2025-07-02T06:48:21.161390Z",
     "shell.execute_reply.started": "2025-07-02T06:48:20.588527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_path = \"/root/nfs/hmj/ImP/MyTest/BUDA-Net/datasets/gopro_deblur\"\n",
    "blur_dir = os.path.join(base_path, \"blur\", \"images\")\n",
    "sharp_dir = os.path.join(base_path, \"sharp\", \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:48:21.163510Z",
     "iopub.status.busy": "2025-07-02T06:48:21.163249Z",
     "iopub.status.idle": "2025-07-02T06:48:21.178467Z",
     "shell.execute_reply": "2025-07-02T06:48:21.177677Z",
     "shell.execute_reply.started": "2025-07-02T06:48:21.163477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:48:21.190788Z",
     "iopub.status.busy": "2025-07-02T06:48:21.190558Z",
     "iopub.status.idle": "2025-07-02T06:48:24.361491Z",
     "shell.execute_reply": "2025-07-02T06:48:24.360832Z",
     "shell.execute_reply.started": "2025-07-02T06:48:21.190769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\")\n",
    "image_pairs = []\n",
    "\n",
    "for filename in os.listdir(blur_dir):\n",
    "    if not filename.lower().endswith(image_exts):\n",
    "        continue\n",
    "\n",
    "    blur_path = os.path.join(blur_dir, filename)\n",
    "    sharp_path = os.path.join(sharp_dir, filename)\n",
    "\n",
    "    if os.path.isfile(blur_path) and os.path.isfile(sharp_path):\n",
    "        image_pairs.append((blur_path, sharp_path))\n",
    "\n",
    "print(f\"Total image pairs found: {len(image_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:48:32.909449Z",
     "iopub.status.busy": "2025-07-02T06:48:32.908966Z",
     "iopub.status.idle": "2025-07-02T06:48:33.515149Z",
     "shell.execute_reply": "2025-07-02T06:48:33.514365Z",
     "shell.execute_reply.started": "2025-07-02T06:48:32.909425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "blur_path, sharp_path = image_pairs[0]\n",
    "\n",
    "blur_img = Image.open(blur_path).convert(\"RGB\")\n",
    "sharp_img = Image.open(sharp_path).convert(\"RGB\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Blurry Image\")\n",
    "plt.imshow(blur_img)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Sharp Image\")\n",
    "plt.imshow(sharp_img)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:33:52.503687Z",
     "iopub.status.busy": "2025-06-03T08:33:52.502999Z",
     "iopub.status.idle": "2025-06-03T08:33:52.508621Z",
     "shell.execute_reply": "2025-06-03T08:33:52.507878Z",
     "shell.execute_reply.started": "2025-06-03T08:33:52.503663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BlurSharpDataset(Dataset):\n",
    "    def __init__(self, image_pairs, transform=None):\n",
    "        self.image_pairs = image_pairs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        blur_path, sharp_path = self.image_pairs[idx]\n",
    "        blur = Image.open(blur_path).convert(\"RGB\")\n",
    "        sharp = Image.open(sharp_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            blur = self.transform(blur)\n",
    "            sharp = self.transform(sharp)\n",
    "\n",
    "        return blur, sharp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我们的粗糙数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "class GoProDataset(Dataset):\n",
    "    \"\"\"\n",
    "    GoPro dataset with structure:\n",
    "    root/gopro\n",
    "      ├── blur/image/*.png\n",
    "      └── sharp/image/*.png\n",
    "\n",
    "    Train / test split is done by index.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        split=\"train\",\n",
    "        crop_size=256,\n",
    "        training=True,\n",
    "        train_ratio=0.8,\n",
    "        extensions=(\".png\", \".jpg\", \".jpeg\")\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blur_dir = os.path.join(root, \"blur\", \"images\")\n",
    "        self.sharp_dir = os.path.join(root, \"sharp\", \"images\")\n",
    "\n",
    "        assert os.path.isdir(self.blur_dir), f\"Not found: {self.blur_dir}\"\n",
    "        assert os.path.isdir(self.sharp_dir), f\"Not found: {self.sharp_dir}\"\n",
    "\n",
    "        names = [\n",
    "            f for f in os.listdir(self.blur_dir)\n",
    "            if f.lower().endswith(extensions)\n",
    "        ]\n",
    "        names.sort()\n",
    "\n",
    "        # ---- train / test split ----\n",
    "        split_idx = int(len(names) * train_ratio)\n",
    "        if split == \"train\":\n",
    "            self.names = names[:split_idx]\n",
    "        elif split == \"test\":\n",
    "            self.names = names[split_idx:]\n",
    "        else:\n",
    "            raise ValueError(\"split must be 'train' or 'test'\")\n",
    "\n",
    "        self.crop_size = crop_size\n",
    "        self.training = training\n",
    "\n",
    "        print(\n",
    "            f\"[GoProDataset] split={split}, \"\n",
    "            f\"samples={len(self.names)}\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def _random_crop(self, img1, img2):\n",
    "        w, h = img1.size\n",
    "        cs = self.crop_size\n",
    "\n",
    "        if w < cs or h < cs:\n",
    "            img1 = TF.resize(img1, (cs, cs))\n",
    "            img2 = TF.resize(img2, (cs, cs))\n",
    "            return img1, img2\n",
    "\n",
    "        x = random.randint(0, w - cs)\n",
    "        y = random.randint(0, h - cs)\n",
    "        img1 = TF.crop(img1, y, x, cs, cs)\n",
    "        img2 = TF.crop(img2, y, x, cs, cs)\n",
    "        return img1, img2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.names[idx]\n",
    "\n",
    "        blur = Image.open(os.path.join(self.blur_dir, name)).convert(\"RGB\")\n",
    "        sharp = Image.open(os.path.join(self.sharp_dir, name)).convert(\"RGB\")\n",
    "\n",
    "        if self.training:\n",
    "            blur, sharp = self._random_crop(blur, sharp)\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                blur = TF.hflip(blur)\n",
    "                sharp = TF.hflip(sharp)\n",
    "            if random.random() < 0.5:\n",
    "                blur = TF.vflip(blur)\n",
    "                sharp = TF.vflip(sharp)\n",
    "\n",
    "        blur = TF.to_tensor(blur)\n",
    "        sharp = TF.to_tensor(sharp)\n",
    "        return blur, sharp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:33:52.675516Z",
     "iopub.status.busy": "2025-06-03T08:33:52.674953Z",
     "iopub.status.idle": "2025-06-03T08:33:52.679260Z",
     "shell.execute_reply": "2025-06-03T08:33:52.678688Z",
     "shell.execute_reply.started": "2025-06-03T08:33:52.675493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    #transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #transforms.RandomRotation(degrees=5),\n",
    "    #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:33:52.866977Z",
     "iopub.status.busy": "2025-06-03T08:33:52.866436Z",
     "iopub.status.idle": "2025-06-03T08:39:29.652962Z",
     "shell.execute_reply": "2025-06-03T08:39:29.652125Z",
     "shell.execute_reply.started": "2025-06-03T08:33:52.866954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def to_gray_np(img):\n",
    "    img_np = np.array(img.convert(\"RGB\")) / 255.0\n",
    "    gray = np.dot(img_np[..., :3], [0.299, 0.587, 0.114])\n",
    "    return gray\n",
    "\n",
    "filtered_pairs = []\n",
    "\n",
    "# for blur_path, sharp_path in tqdm(image_pairs, desc='Computing SSIM'):\n",
    "#     blur_img = Image.open(blur_path)\n",
    "#     sharp_img = Image.open(sharp_path)\n",
    "\n",
    "#     blur_gray = to_gray_np(blur_img)\n",
    "#     sharp_gray = to_gray_np(sharp_img)\n",
    "\n",
    "#     ssim_score = ssim(blur_gray, sharp_gray, data_range=1.0)\n",
    "\n",
    "#     if ssim_score <= 0.8:\n",
    "#         filtered_pairs.append((blur_path, sharp_path))\n",
    "\n",
    "# print(f\"Total original pairs: {len(image_pairs)}\")\n",
    "# print(f\"Filtered (SSIM <= 0.8): {len(filtered_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:39:29.654293Z",
     "iopub.status.busy": "2025-06-03T08:39:29.654019Z",
     "iopub.status.idle": "2025-06-03T08:39:29.660807Z",
     "shell.execute_reply": "2025-06-03T08:39:29.660263Z",
     "shell.execute_reply.started": "2025-06-03T08:39:29.654274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# full_dataset = BlurSharpDataset(image_pairs=filtered_pairs, transform=transform)\n",
    "\n",
    "# train_size = int(0.8 * len(full_dataset))\n",
    "# val_size = len(full_dataset) - train_size\n",
    "\n",
    "# train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        GoProDataset(\"/root/nfs/hmj/ImP/MyTest/BUDA-Net/datasets/gopro_deblur\", \"train\",256, True),\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        # num_workers=args.num_workers,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "        GoProDataset(\"/root/nfs/hmj/ImP/MyTest/BUDA-Net/datasets/gopro_deblur\", \"test\", 256, False),\n",
    "        batch_size=1, shuffle=False, \n",
    "        # num_workers=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:05.320483Z",
     "iopub.status.busy": "2025-06-03T08:40:05.320222Z",
     "iopub.status.idle": "2025-06-03T08:40:05.326118Z",
     "shell.execute_reply": "2025-06-03T08:40:05.325264Z",
     "shell.execute_reply.started": "2025-06-03T08:40:05.320466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DeblurCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeblurCNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:11.263480Z",
     "iopub.status.busy": "2025-06-03T08:40:11.262873Z",
     "iopub.status.idle": "2025-06-03T08:40:11.268559Z",
     "shell.execute_reply": "2025-06-03T08:40:11.267765Z",
     "shell.execute_reply.started": "2025-06-03T08:40:11.263453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_dropout=False):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if use_dropout:\n",
    "            layers.insert(3, nn.Dropout(0.2))\n",
    "\n",
    "        self.conv_block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:11.447605Z",
     "iopub.status.busy": "2025-06-03T08:40:11.447298Z",
     "iopub.status.idle": "2025-06-03T08:40:11.452530Z",
     "shell.execute_reply": "2025-06-03T08:40:11.451755Z",
     "shell.execute_reply.started": "2025-06-03T08:40:11.447583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            ConvBlock(in_channels, out_channels, use_dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:11.638189Z",
     "iopub.status.busy": "2025-06-03T08:40:11.637511Z",
     "iopub.status.idle": "2025-06-03T08:40:11.645182Z",
     "shell.execute_reply": "2025-06-03T08:40:11.644231Z",
     "shell.execute_reply.started": "2025-06-03T08:40:11.638161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding = 1)\n",
    "        self.conv = ConvBlock(in_channels, out_channels, use_dropout)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.upconv(x1)\n",
    "\n",
    "        if x1.size() != x2.size():\n",
    "            x1 = F.interpolate(x1, size=x2.size()[2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:11.816554Z",
     "iopub.status.busy": "2025-06-03T08:40:11.816281Z",
     "iopub.status.idle": "2025-06-03T08:40:11.823293Z",
     "shell.execute_reply": "2025-06-03T08:40:11.822325Z",
     "shell.execute_reply.started": "2025-06-03T08:40:11.816535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, use_dropout=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_conv = ConvBlock(in_channels, 64, use_dropout)\n",
    "\n",
    "        self.enc1 = Encoder(64, 128, use_dropout)\n",
    "        self.enc2 = Encoder(128, 256, use_dropout)\n",
    "        self.enc3 = Encoder(256, 512, use_dropout)\n",
    "        self.enc4 = Encoder(512, 1024, use_dropout)\n",
    "\n",
    "        self.dec1 = Decoder(1024, 512, use_dropout)\n",
    "        self.dec2 = Decoder(512, 256, use_dropout)\n",
    "        self.dec3 = Decoder(256, 128, use_dropout)\n",
    "        self.dec4 = Decoder(128, 64, use_dropout)\n",
    "\n",
    "        self.out_conv = nn.Sequential(\n",
    "            nn.Conv2d(64, out_channels, kernel_size=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.in_conv(x)\n",
    "        \n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        x5 = self.enc4(x4)\n",
    "\n",
    "        x = self.dec1(x5, x4)\n",
    "        x = self.dec2(x, x3)\n",
    "        x = self.dec3(x, x2)\n",
    "        x = self.dec4(x, x1)\n",
    "\n",
    "        return self.out_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:12.194152Z",
     "iopub.status.busy": "2025-06-03T08:40:12.193850Z",
     "iopub.status.idle": "2025-06-03T08:40:12.199009Z",
     "shell.execute_reply": "2025-06-03T08:40:12.198386Z",
     "shell.execute_reply.started": "2025-06-03T08:40:12.194131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3),\n",
    "            nn.InstanceNorm2d(in_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:12.382857Z",
     "iopub.status.busy": "2025-06-03T08:40:12.382293Z",
     "iopub.status.idle": "2025-06-03T08:40:12.389943Z",
     "shell.execute_reply": "2025-06-03T08:40:12.389115Z",
     "shell.execute_reply.started": "2025-06-03T08:40:12.382836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_nc=3, output_nc=3, num_resnet_blocks=9, final_activation='tanh'):\n",
    "        super(ResNet, self).__init__()\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=7),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "\n",
    "        # Downsampling Layers\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features *= 2\n",
    "\n",
    "        # Residual Blocks\n",
    "        for _ in range(num_resnet_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling layers\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features //= 2\n",
    "\n",
    "        # Output layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, output_nc, kernel_size=7)\n",
    "        ]\n",
    "\n",
    "        # Final activation\n",
    "        if final_activation == 'tanh':\n",
    "            model += [nn.Tanh()]\n",
    "        elif final_activation == 'sigmoid':\n",
    "            model += [nn.Sigmoid()]\n",
    "        elif final_activation != 'none':\n",
    "            raise ValueError(\"Final_activation must be 'tanh', 'sigmoid', or 'none'\")\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T10:58:29.699208Z",
     "iopub.status.busy": "2025-06-22T10:58:29.698306Z",
     "iopub.status.idle": "2025-06-22T10:58:29.704226Z",
     "shell.execute_reply": "2025-06-22T10:58:29.703391Z",
     "shell.execute_reply.started": "2025-06-22T10:58:29.699178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        vgg = models.vgg16(pretrained=True).features[:16]\n",
    "        for param in vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vgg = vgg.eval().to(device)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # input and target: [B, 3, H, W], normalized to [0, 1]\n",
    "        return F.l1_loss(self.vgg(input), self.vgg(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T10:58:29.879204Z",
     "iopub.status.busy": "2025-06-22T10:58:29.878714Z",
     "iopub.status.idle": "2025-06-22T10:58:29.883337Z",
     "shell.execute_reply": "2025-06-22T10:58:29.882683Z",
     "shell.execute_reply.started": "2025-06-22T10:58:29.879180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "imagenet_norm = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def preprocess_for_vgg(tensor):\n",
    "    return imagenet_norm((tensor * 0.5) + 0.5) # from [-1, 1] -> [0, 1] -> normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:13.185782Z",
     "iopub.status.busy": "2025-06-03T08:40:13.185548Z",
     "iopub.status.idle": "2025-06-03T08:40:17.644793Z",
     "shell.execute_reply": "2025-06-03T08:40:17.644078Z",
     "shell.execute_reply.started": "2025-06-03T08:40:13.185766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "percep_loss = PerceptualLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:17.646330Z",
     "iopub.status.busy": "2025-06-03T08:40:17.646026Z",
     "iopub.status.idle": "2025-06-03T08:40:17.650321Z",
     "shell.execute_reply": "2025-06-03T08:40:17.649738Z",
     "shell.execute_reply.started": "2025-06-03T08:40:17.646305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def total_loss(pred, target):\n",
    "    pred_vgg = preprocess_for_vgg(pred)\n",
    "    target_vgg = preprocess_for_vgg(target)\n",
    "    return 0.2 * mse_loss(pred, target) + 0.8 * percep_loss(pred_vgg, target_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN & UNet Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:17.651189Z",
     "iopub.status.busy": "2025-06-03T08:40:17.650930Z",
     "iopub.status.idle": "2025-06-03T08:40:17.666589Z",
     "shell.execute_reply": "2025-06-03T08:40:17.665958Z",
     "shell.execute_reply.started": "2025-06-03T08:40:17.651167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for blur_imgs, sharp_imgs in dataloader:\n",
    "            blur_imgs = blur_imgs.to(device)\n",
    "            sharp_imgs = sharp_imgs.to(device)\n",
    "            outputs = model(blur_imgs)\n",
    "\n",
    "            loss = total_loss(outputs, sharp_imgs) # Custom loss\n",
    "            total += loss.item()\n",
    "    return total / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:17.668015Z",
     "iopub.status.busy": "2025-06-03T08:40:17.667759Z",
     "iopub.status.idle": "2025-06-03T08:40:17.682796Z",
     "shell.execute_reply": "2025-06-03T08:40:17.682128Z",
     "shell.execute_reply.started": "2025-06-03T08:40:17.667992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # ✅ 每个 epoch 都切回 train\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for blur_imgs, sharp_imgs in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            blur_imgs = blur_imgs.to(device, non_blocking=True)\n",
    "            sharp_imgs = sharp_imgs.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast():  # ✅ AMP\n",
    "                outputs = model(blur_imgs)\n",
    "                loss = total_loss(outputs, sharp_imgs)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        avg_val_loss = evaluate_model(model, val_loader)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "            f\"- Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# def train_model(model, train_loader, val_loader, optimizer, num_epochs):\n",
    "#     model.train()\n",
    "#     for epoch in range(num_epochs):\n",
    "#         running_loss = 0.0\n",
    "#         for blur_imgs, sharp_imgs in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "#             blur_imgs = blur_imgs.to(device)\n",
    "#             sharp_imgs = sharp_imgs.to(device)\n",
    "\n",
    "#             outputs = model(blur_imgs)\n",
    "#             loss = total_loss(outputs, sharp_imgs) # Custom loss\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "\n",
    "#         avg_train_loss = running_loss / len(train_loader)\n",
    "#         avg_val_loss = evaluate_model(model, val_loader)\n",
    "\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T16:01:11.312649Z",
     "iopub.status.busy": "2025-06-02T16:01:11.312314Z",
     "iopub.status.idle": "2025-06-02T18:06:33.815135Z",
     "shell.execute_reply": "2025-06-02T18:06:33.814307Z",
     "shell.execute_reply.started": "2025-06-02T16:01:11.312626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_cnn = DeblurCNN().to(device)\n",
    "optimizer_cnn = torch.optim.Adam(model_cnn.parameters(), lr=1e-4)\n",
    "\n",
    "train_model(model_cnn, train_loader, val_loader, optimizer_cnn, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T18:06:33.817135Z",
     "iopub.status.busy": "2025-06-02T18:06:33.816654Z",
     "iopub.status.idle": "2025-06-02T18:06:33.827244Z",
     "shell.execute_reply": "2025-06-02T18:06:33.826660Z",
     "shell.execute_reply.started": "2025-06-02T18:06:33.817114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_cnn.state_dict(), \"CNN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T18:06:33.828108Z",
     "iopub.status.busy": "2025-06-02T18:06:33.827870Z",
     "iopub.status.idle": "2025-06-02T20:31:59.315261Z",
     "shell.execute_reply": "2025-06-02T20:31:59.314664Z",
     "shell.execute_reply.started": "2025-06-02T18:06:33.828089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_unet = UNet().to(device)\n",
    "optimizer_unet = torch.optim.Adam(model_unet.parameters(), lr=1e-4)\n",
    "\n",
    "train_model(model_unet, train_loader, val_loader, optimizer_unet, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T20:31:59.317102Z",
     "iopub.status.busy": "2025-06-02T20:31:59.316905Z",
     "iopub.status.idle": "2025-06-02T20:31:59.584132Z",
     "shell.execute_reply": "2025-06-02T20:31:59.583591Z",
     "shell.execute_reply.started": "2025-06-02T20:31:59.317087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_unet.state_dict(), \"UNet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN GAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:18.466049Z",
     "iopub.status.busy": "2025-06-03T08:40:18.465781Z",
     "iopub.status.idle": "2025-06-03T08:40:18.471936Z",
     "shell.execute_reply": "2025-06-03T08:40:18.471097Z",
     "shell.execute_reply.started": "2025-06-03T08:40:18.466029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNNGenerator(nn.Module):\n",
    "    def __init__(self, use_dropout=False):\n",
    "        super(CNNGenerator, self).__init__()\n",
    "        dropout = lambda: nn.Dropout(0.5) if use_dropout else nn.Identity()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            dropout(),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            dropout(),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            dropout()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, kernel_size=3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:33.696747Z",
     "iopub.status.busy": "2025-06-03T08:40:33.696052Z",
     "iopub.status.idle": "2025-06-03T08:40:33.699862Z",
     "shell.execute_reply": "2025-06-03T08:40:33.699008Z",
     "shell.execute_reply.started": "2025-06-03T08:40:33.696726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Discriminator is the same as UNet GAN (PatchGAN)\n",
    "\n",
    "# Loss is the same as UNet GAN (Adversarial(BCE), L1, Perceptual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet GAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:34.046854Z",
     "iopub.status.busy": "2025-06-03T08:40:34.046591Z",
     "iopub.status.idle": "2025-06-03T08:40:34.053397Z",
     "shell.execute_reply": "2025-06-03T08:40:34.052729Z",
     "shell.execute_reply.started": "2025-06-03T08:40:34.046835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generator (U-Net)\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, use_dropout=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_conv = ConvBlock(in_channels, 64, use_dropout)\n",
    "        self.enc1 = Encoder(64, 128, use_dropout)\n",
    "        self.enc2 = Encoder(128, 256, use_dropout)\n",
    "        self.enc3 = Encoder(256, 512, use_dropout)\n",
    "        self.enc4 = Encoder(512, 1024, use_dropout)\n",
    "\n",
    "        self.dec1 = Decoder(1024, 512, use_dropout)\n",
    "        self.dec2 = Decoder(512, 256, use_dropout)\n",
    "        self.dec3 = Decoder(256, 128, use_dropout)\n",
    "        self.dec4 = Decoder(128, 64, use_dropout)\n",
    "\n",
    "        self.out_conv = nn.Sequential(\n",
    "            nn.Conv2d(64, out_channels, kernel_size=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.in_conv(x)\n",
    "        x2 = self.enc1(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.enc3(x3)\n",
    "        x5 = self.enc4(x4)\n",
    "\n",
    "        x = self.dec1(x5, x4)\n",
    "        x = self.dec2(x, x3)\n",
    "        x = self.dec3(x, x2)\n",
    "        x = self.dec4(x, x1)\n",
    "\n",
    "        return self.out_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:34.240818Z",
     "iopub.status.busy": "2025-06-03T08:40:34.240543Z",
     "iopub.status.idle": "2025-06-03T08:40:34.246253Z",
     "shell.execute_reply": "2025-06-03T08:40:34.245377Z",
     "shell.execute_reply.started": "2025-06-03T08:40:34.240798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, use_dropout=False):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        ]\n",
    "        if use_dropout:\n",
    "            layers.append(nn.Dropout(0.3))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:34.429223Z",
     "iopub.status.busy": "2025-06-03T08:40:34.428535Z",
     "iopub.status.idle": "2025-06-03T08:40:34.434590Z",
     "shell.execute_reply": "2025-06-03T08:40:34.433981Z",
     "shell.execute_reply.started": "2025-06-03T08:40:34.429181Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Discriminator (PatchGAN)\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=6, use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.layer1 = DiscriminatorBlock(64, 128, stride=2, use_dropout=use_dropout)\n",
    "        self.layer2 = DiscriminatorBlock(128, 256, stride=2, use_dropout=use_dropout)\n",
    "        self.layer3 = DiscriminatorBlock(256, 512, stride=1, use_dropout=use_dropout)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:34.624030Z",
     "iopub.status.busy": "2025-06-03T08:40:34.623545Z",
     "iopub.status.idle": "2025-06-03T08:40:34.629730Z",
     "shell.execute_reply": "2025-06-03T08:40:34.629132Z",
     "shell.execute_reply.started": "2025-06-03T08:40:34.624009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.percep = PerceptualLoss()\n",
    "\n",
    "    def discriminator_loss(self, real_preds, fake_preds, smoothing=0.1):\n",
    "        real_labels = torch.ones_like(real_preds) * (1.0 - smoothing)\n",
    "        fake_labels = torch.zeros_like(fake_preds) * 0.2\n",
    "        loss_real = self.bce(real_preds, fake_labels)\n",
    "        loss_fake = self.bce(fake_preds, real_labels)\n",
    "        return 0.5 * (loss_real + loss_fake)\n",
    "\n",
    "    def generator_loss(self, fake_preds, fake_imgs, real_imgs, \n",
    "                       adv_weight=0.001, pixel_weight=0.5, perceptual_weight=0.5):\n",
    "        real_labels = torch.ones_like(fake_preds)\n",
    "        adv_loss = self.bce(fake_preds, real_labels)\n",
    "        l1_loss = self.l1(fake_imgs, real_imgs)\n",
    "        perceptual_loss = self.percep(preprocess_for_vgg(fake_imgs), preprocess_for_vgg(real_imgs))\n",
    "        return adv_weight * adv_loss + pixel_weight * l1_loss + perceptual_weight * perceptual_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet GAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:35.007961Z",
     "iopub.status.busy": "2025-06-03T08:40:35.007270Z",
     "iopub.status.idle": "2025-06-03T08:40:35.014823Z",
     "shell.execute_reply": "2025-06-03T08:40:35.013879Z",
     "shell.execute_reply.started": "2025-06-03T08:40:35.007938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generator (ResNet)\n",
    "class ResNetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc=3, output_nc=3, num_resnet_blocks=9, use_dropout=False):\n",
    "        super(ResNetGenerator, self).__init__()\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=7),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features *= 2\n",
    "\n",
    "        # Residual Blocks\n",
    "        for _ in range(num_resnet_blocks):\n",
    "            block = [ResidualBlock(in_features)]\n",
    "            if use_dropout:\n",
    "                block.append(nn.Dropout(0.5))\n",
    "            model += block\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, \n",
    "                                  padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features //= 2\n",
    "\n",
    "        # Output layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, output_nc, kernel_size=7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:35.231694Z",
     "iopub.status.busy": "2025-06-03T08:40:35.231164Z",
     "iopub.status.idle": "2025-06-03T08:40:35.234706Z",
     "shell.execute_reply": "2025-06-03T08:40:35.234041Z",
     "shell.execute_reply.started": "2025-06-03T08:40:35.231672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Discriminator is the same as UNet GAN (PatchGAN)\n",
    "\n",
    "# Loss is the same as UNet GAN (Adversarial(BCE), L1, Perceptual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet GAN Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:36.187699Z",
     "iopub.status.busy": "2025-06-03T08:40:36.187441Z",
     "iopub.status.idle": "2025-06-03T08:40:36.195494Z",
     "shell.execute_reply": "2025-06-03T08:40:36.194849Z",
     "shell.execute_reply.started": "2025-06-03T08:40:36.187682Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, train_loader, val_loader, optimizer_G, optimizer_D, loss_fn, device, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        running_d_loss = 0.0\n",
    "        running_g_loss = 0.0\n",
    "\n",
    "        for real_blur, real_sharp in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Train\"):\n",
    "            real_blur, real_sharp = real_blur.to(device), real_sharp.to(device)\n",
    "            fake_sharp = generator(real_blur)\n",
    "\n",
    "            real_pair = torch.cat((real_blur, real_sharp), dim=1)\n",
    "            fake_pair = torch.cat((real_blur, fake_sharp.detach()), dim=1)\n",
    "            d_real = discriminator(real_pair)\n",
    "            d_fake = discriminator(fake_pair)\n",
    "            d_loss = loss_fn.discriminator_loss(d_real, d_fake)\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            fake_pair = torch.cat((real_blur, fake_sharp), dim=1)\n",
    "            d_fake_pred = discriminator(fake_pair)\n",
    "            g_loss = loss_fn.generator_loss(d_fake_pred, fake_sharp, real_sharp)\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            running_d_loss += d_loss.item()\n",
    "            running_g_loss += g_loss.item()\n",
    "\n",
    "        avg_d_loss = running_d_loss / len(train_loader)\n",
    "        avg_g_loss = running_g_loss / len(train_loader)\n",
    "\n",
    "        generator.eval()\n",
    "        discriminator.eval()\n",
    "        val_g_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_blur, val_sharp in val_loader:\n",
    "                val_blur, val_sharp = val_blur.to(device), val_sharp.to(device)\n",
    "                val_fake = generator(val_blur)\n",
    "                val_fake_pair = torch.cat((val_blur, val_fake), dim=1)\n",
    "                d_fake_pred_val = discriminator(val_fake_pair)\n",
    "                val_g_loss += loss_fn.generator_loss(d_fake_pred_val, val_fake, val_sharp).item()\n",
    "\n",
    "        avg_val_g_loss = val_g_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: D Loss = {avg_d_loss:.4f}, G Loss = {avg_g_loss:.4f}, Val G Loss = {avg_val_g_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-02T20:31:59.661476Z",
     "iopub.status.busy": "2025-06-02T20:31:59.661269Z",
     "iopub.status.idle": "2025-06-02T23:29:51.677487Z",
     "shell.execute_reply": "2025-06-02T23:29:51.676775Z",
     "shell.execute_reply.started": "2025-06-02T20:31:59.661456Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss_fn = GANLoss()\n",
    "\n",
    "generator_unet = UNetGenerator(use_dropout=False).to(device)\n",
    "discriminator_patch = PatchDiscriminator(use_dropout=True).to(device)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator_unet.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator_patch.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "\n",
    "train_gan(generator_unet, discriminator_patch, train_loader, val_loader, optimizer_G, optimizer_D, loss_fn, device, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T23:29:51.678647Z",
     "iopub.status.busy": "2025-06-02T23:29:51.678409Z",
     "iopub.status.idle": "2025-06-02T23:29:51.936919Z",
     "shell.execute_reply": "2025-06-02T23:29:51.936110Z",
     "shell.execute_reply.started": "2025-06-02T23:29:51.678625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(generator_unet.state_dict(), \"GAN_UNet_Generator.pth\")\n",
    "torch.save(discriminator_patch.state_dict(), \"GAN_Patch_Discriminator.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:41.187916Z",
     "iopub.status.busy": "2025-06-03T08:40:41.187644Z",
     "iopub.status.idle": "2025-06-03T08:40:42.078279Z",
     "shell.execute_reply": "2025-06-03T08:40:42.077462Z",
     "shell.execute_reply.started": "2025-06-03T08:40:41.187897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_cnn = DeblurCNN().to(device)\n",
    "model_unet = UNet().to(device)\n",
    "model_resnet = ResNet().to(device)\n",
    "\n",
    "generator_cnn = CNNGenerator(use_dropout=False).to(device)\n",
    "generator_unet = UNetGenerator(use_dropout=False).to(device)\n",
    "generator_resnet = ResNetGenerator(use_dropout=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:40:44.831971Z",
     "iopub.status.busy": "2025-06-03T08:40:44.831638Z",
     "iopub.status.idle": "2025-06-03T08:40:48.081010Z",
     "shell.execute_reply": "2025-06-03T08:40:48.080236Z",
     "shell.execute_reply.started": "2025-06-03T08:40:44.831948Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "model_cnn.load_state_dict(torch.load(\"/kaggle/input/deblur-image-phase-1/pytorch/prototype/1/CNN.pth\", device))\n",
    "# UNet\n",
    "model_unet.load_state_dict(torch.load(\"/kaggle/input/deblur-image-phase-1/pytorch/prototype/1/UNet.pth\", device))\n",
    "# ResNet\n",
    "model_resnet.load_state_dict(torch.load(\"/kaggle/input/deblur-image-phase-1/pytorch/prototype/1/ResNet.pth\", device))\n",
    "\n",
    "# GAN CNN\n",
    "generator_cnn.load_state_dict(torch.load(\"/kaggle/input/deblur-image-phase-1/pytorch/prototype/1/GAN_CNN_Generator.pth\", device))\n",
    "# GAN UNet\n",
    "generator_unet.load_state_dict(torch.load(\"/kaggle/input/deblur-image-phase-1/pytorch/prototype/1/GAN_UNet_Generator.pth\", device))\n",
    "# GAN ResNet\n",
    "generator_resnet.load_state_dict(torch.load(\"/kaggle/input/deblur-image-phase-1/pytorch/prototype/1/GAN_ResNet_Generator.pth\", device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:41:05.632383Z",
     "iopub.status.busy": "2025-06-03T08:41:05.631771Z",
     "iopub.status.idle": "2025-06-03T08:41:05.636052Z",
     "shell.execute_reply": "2025-06-03T08:41:05.635428Z",
     "shell.execute_reply.started": "2025-06-03T08:41:05.632359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def denorm(t):\n",
    "    return (t * 0.5) + 0.5\n",
    "\n",
    "def to_gray(img):\n",
    "    return np.dot(img[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:41:05.857638Z",
     "iopub.status.busy": "2025-06-03T08:41:05.857024Z",
     "iopub.status.idle": "2025-06-03T08:41:05.864626Z",
     "shell.execute_reply": "2025-06-03T08:41:05.863859Z",
     "shell.execute_reply.started": "2025-06-03T08:41:05.857614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def model_evaluation(model, dataloader, device, max_batches=None, verbose=False):\n",
    "    model.eval()\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (blur_img, sharp_img) in enumerate(dataloader):\n",
    "            if max_batches is not None and i >= max_batches:\n",
    "                break\n",
    "\n",
    "            input_tensor = blur_img.to(device)\n",
    "            target_tensor = sharp_img.to(device)\n",
    "\n",
    "            output = model(input_tensor).cpu()\n",
    "            target_tensor = target_tensor.cpu()\n",
    "\n",
    "            for pred, target in zip(output, target_tensor):\n",
    "                pred_np = denorm(pred).clamp(0, 1).permute(1, 2, 0).numpy()\n",
    "                target_np = denorm(target).clamp(0, 1).permute(1, 2, 0).numpy()\n",
    "\n",
    "                pred_gray = to_gray(pred_np)\n",
    "                target_gray = to_gray(target_np)\n",
    "\n",
    "                psnr_val = psnr(target_np, pred_np, data_range=1.0)\n",
    "                ssim_val = ssim(target_gray, pred_gray, data_range=1.0)\n",
    "\n",
    "                total_psnr += psnr_val\n",
    "                total_ssim += ssim_val\n",
    "                count += 1\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"Sample {count}: PSNR={psnr_val:.2f}, SSIM={ssim_val:.4f}\")\n",
    "\n",
    "    if count == 0:\n",
    "        raise ValueError(\"No samples were evaluated\")\n",
    "\n",
    "    avg_psnr = total_psnr / count if count != 0 else 0\n",
    "    avg_ssim = total_ssim / count if count != 0 else 0\n",
    "\n",
    "    return avg_psnr, avg_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:41:06.114256Z",
     "iopub.status.busy": "2025-06-03T08:41:06.113893Z",
     "iopub.status.idle": "2025-06-03T08:42:30.240108Z",
     "shell.execute_reply": "2025-06-03T08:42:30.239401Z",
     "shell.execute_reply.started": "2025-06-03T08:41:06.114234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "psnr_cnn, ssim_cnn = model_evaluation(model_cnn, val_loader, device, max_batches=None)\n",
    "psnr_unet, ssim_unet = model_evaluation(model_unet, val_loader, device, max_batches=None)\n",
    "psnr_resnet, ssim_resnet = model_evaluation(model_resnet, val_loader, device, max_batches=None)\n",
    "\n",
    "psnr_gan_cnn, ssim_gan_cnn = model_evaluation(generator_cnn, val_loader, device, max_batches=None)\n",
    "psnr_gan_unet, ssim_gan_unet = model_evaluation(generator_unet, val_loader, device, max_batches=None)\n",
    "psnr_gan_resnet, ssim_gan_resnet = model_evaluation(generator_resnet, val_loader, device, max_batches=None)\n",
    "\n",
    "print(f\"{'Model':<15}{'PSNR (dB)':>12}{'SSIM':>12}\")\n",
    "print(\"-\" * 39)\n",
    "\n",
    "print(f\"{'CNN':<15}{psnr_cnn:>12.2f}{ssim_cnn:>12.4f}\")\n",
    "print(f\"{'UNet':<15}{psnr_unet:>12.2f}{ssim_unet:>12.4f}\")\n",
    "print(f\"{'ResNet':<15}{psnr_resnet:>12.2f}{ssim_resnet:>12.4f}\")\n",
    "\n",
    "print(f\"{'GAN CNN':<15}{psnr_gan_cnn:>12.2f}{ssim_gan_cnn:>12.4f}\")\n",
    "print(f\"{'GAN UNet':<15}{psnr_gan_unet:>12.2f}{ssim_gan_unet:>12.4f}\")\n",
    "print(f\"{'GAN ResNet':<15}{psnr_gan_resnet:>12.2f}{ssim_gan_resnet:>12.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:47:15.033485Z",
     "iopub.status.busy": "2025-06-03T08:47:15.033221Z",
     "iopub.status.idle": "2025-06-03T08:47:15.369029Z",
     "shell.execute_reply": "2025-06-03T08:47:15.368233Z",
     "shell.execute_reply.started": "2025-06-03T08:47:15.033468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_scores = {\n",
    "    \"CNN\": {\"psnr\": psnr_cnn, \"ssim\": ssim_cnn},\n",
    "    \"UNet\": {\"psnr\": psnr_unet, \"ssim\": ssim_unet},\n",
    "    \"ResNet\": {\"psnr\": psnr_resnet, \"ssim\": ssim_resnet},\n",
    "    \"GAN_CNN\": {\"psnr\": psnr_gan_cnn, \"ssim\": ssim_gan_cnn},\n",
    "    \"GAN_UNet\": {\"psnr\": psnr_gan_unet, \"ssim\": ssim_gan_unet},\n",
    "    \"GAN_ResNet\": {\"psnr\": psnr_gan_resnet, \"ssim\": ssim_gan_resnet}\n",
    "}\n",
    "\n",
    "colors = cm.tab10(np.linspace(0, 1, len(model_scores)))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "texts = []\n",
    "\n",
    "for (model, scores), color in zip(model_scores.items(), colors):\n",
    "    plt.scatter(scores[\"psnr\"], scores[\"ssim\"], color=color, s=100)\n",
    "    texts.append(\n",
    "        plt.text(scores[\"psnr\"], scores[\"ssim\"], model, fontsize=11)\n",
    "    )\n",
    "\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle=\"->\", color='gray', lw=0.5))\n",
    "\n",
    "plt.xlabel(\"PSNR (dB)\")\n",
    "plt.ylabel(\"SSIM\")\n",
    "plt.title(\"Model Comparison: PSNR vs SSIM\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:47:24.735977Z",
     "iopub.status.busy": "2025-06-03T08:47:24.735405Z",
     "iopub.status.idle": "2025-06-03T08:47:24.741060Z",
     "shell.execute_reply": "2025-06-03T08:47:24.740380Z",
     "shell.execute_reply.started": "2025-06-03T08:47:24.735957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_visuals(index, model):\n",
    "    blur_img, sharp_img = full_dataset[index]\n",
    "    with torch.no_grad():\n",
    "        input_tensor = blur_img.unsqueeze(0).to(device)\n",
    "        output_tensor = model(input_tensor).squeeze(0).cpu()\n",
    "\n",
    "    blur_np = denorm(blur_img).permute(1, 2, 0).clamp(0, 1).numpy()\n",
    "    pred_np = denorm(output_tensor).permute(1, 2, 0).clamp(0, 1).numpy()\n",
    "    sharp_np = denorm(sharp_img).permute(1, 2, 0).clamp(0, 1).numpy()\n",
    "\n",
    "    return blur_np, pred_np, sharp_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:47:24.896997Z",
     "iopub.status.busy": "2025-06-03T08:47:24.896448Z",
     "iopub.status.idle": "2025-06-03T08:47:24.902255Z",
     "shell.execute_reply": "2025-06-03T08:47:24.901344Z",
     "shell.execute_reply.started": "2025-06-03T08:47:24.896976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_ssim(models, dataloader, device, amount):\n",
    "    model_ssim_scores = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.eval()\n",
    "\n",
    "        ssim_scores = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(amount):\n",
    "                blur_np, pred_np, sharp_np = get_visuals(i, model)\n",
    "\n",
    "                pred_gray = to_gray(pred_np)\n",
    "                sharp_gray = to_gray(sharp_np)\n",
    "\n",
    "                score = ssim(pred_gray, sharp_gray, data_range=1.0)\n",
    "                ssim_scores.append(score)\n",
    "\n",
    "        model_ssim_scores[model_name] = ssim_scores\n",
    "\n",
    "    return model_ssim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:47:25.047630Z",
     "iopub.status.busy": "2025-06-03T08:47:25.047343Z",
     "iopub.status.idle": "2025-06-03T08:49:10.305592Z",
     "shell.execute_reply": "2025-06-03T08:49:10.304743Z",
     "shell.execute_reply.started": "2025-06-03T08:47:25.047610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"CNN\": model_cnn,\n",
    "    \"UNet\": model_unet,\n",
    "    \"ResNet\": model_resnet, \n",
    "    \"GAN_CNN\": generator_cnn, \n",
    "    \"GAN_UNet\": generator_unet, \n",
    "    \"GAN_ResNet\": generator_resnet\n",
    "}\n",
    "\n",
    "model_ssim_scores = evaluate_ssim(models, val_loader, device, amount=100)\n",
    "\n",
    "# Flatten data\n",
    "df = pd.DataFrame([\n",
    "    {\"Model\": model, \"SSIM\": ssim}\n",
    "    for model, scores in model_ssim_scores.items()\n",
    "    for ssim in scores\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x=\"Model\", y=\"SSIM\", data=df, inner=\"box\", palette=\"Set2\")\n",
    "plt.title(\"SSIM Distribution per Model\")\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:49:10.307478Z",
     "iopub.status.busy": "2025-06-03T08:49:10.307156Z",
     "iopub.status.idle": "2025-06-03T08:49:10.318620Z",
     "shell.execute_reply": "2025-06-03T08:49:10.317924Z",
     "shell.execute_reply.started": "2025-06-03T08:49:10.307443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_best_worst(models, dataloader, device, max_batches):\n",
    "    model_best_worst_scores = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.eval()\n",
    "\n",
    "        ssim_scores = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(max_batches):\n",
    "                blur_np, pred_np, sharp_np = get_visuals(i, model)\n",
    "\n",
    "                pred_gray = to_gray(pred_np)\n",
    "                sharp_gray = to_gray(sharp_np)\n",
    "\n",
    "                score = ssim(pred_gray, sharp_gray, data_range=1.0)\n",
    "                ssim_scores.append(score)\n",
    "\n",
    "        worst_index = int(np.argmin(ssim_scores))\n",
    "        best_index = int(np.argmax(ssim_scores))\n",
    "\n",
    "        worst_blur, worst_pred, worst_sharp = get_visuals(worst_index, model)\n",
    "        best_blur, best_pred, best_sharp = get_visuals(best_index, model)\n",
    "\n",
    "        model_best_worst_scores[model_name] = {\n",
    "            'worst': (worst_blur, worst_pred, worst_sharp, ssim_scores[worst_index]), \n",
    "            'best': (best_blur, best_pred, best_sharp, ssim_scores[best_index])\n",
    "        }\n",
    "\n",
    "    n_models = len(models)\n",
    "    plt.figure(figsize=(12, 4 * n_models))\n",
    "\n",
    "    for i, (model_name, scores) in enumerate(model_best_worst_scores.items()):\n",
    "        worst_blur, worst_pred, worst_sharp, worst_ssim = scores['worst']\n",
    "        best_blur, best_pred, best_sharp, best_ssim = scores['best']\n",
    "\n",
    "        row_offset = i * 2 * 3\n",
    "\n",
    "        # Worst Case\n",
    "        plt.subplot(n_models * 2, 3, row_offset + 1)\n",
    "        plt.title(f\"{model_name} Worst Input/nSSIM: {worst_ssim:.4f})\")\n",
    "        plt.imshow(worst_blur)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(n_models * 2, 3, row_offset + 2)\n",
    "        plt.title(f\"Prediction\")\n",
    "        plt.imshow(worst_pred)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(n_models * 2, 3, row_offset + 3)\n",
    "        plt.title(f\"Ground Truth\")\n",
    "        plt.imshow(worst_sharp)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Best Case\n",
    "        plt.subplot(n_models * 2, 3, row_offset + 4)\n",
    "        plt.title(f\"{model_name} Best Input/nSSIM: {best_ssim:.4f})\")\n",
    "        plt.imshow(best_blur)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(n_models * 2, 3, row_offset + 5)\n",
    "        plt.title(f\"Prediction\")\n",
    "        plt.imshow(best_pred)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(n_models * 2, 3, row_offset + 6)\n",
    "        plt.title(f\"Ground Truth\")\n",
    "        plt.imshow(best_sharp)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:49:10.319562Z",
     "iopub.status.busy": "2025-06-03T08:49:10.319334Z",
     "iopub.status.idle": "2025-06-03T08:49:25.921543Z",
     "shell.execute_reply": "2025-06-03T08:49:25.920582Z",
     "shell.execute_reply.started": "2025-06-03T08:49:10.319544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'CNN': model_cnn,\n",
    "    'UNet': model_unet,\n",
    "    'ResNet': model_resnet,\n",
    "    'GAN_CNN': generator_cnn,\n",
    "    'GAN_UNet': generator_unet,\n",
    "    'GAN_ResNet': generator_resnet\n",
    "}\n",
    "\n",
    "visualize_best_worst(models, val_loader, device, max_batches = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:49:25.923876Z",
     "iopub.status.busy": "2025-06-03T08:49:25.923648Z",
     "iopub.status.idle": "2025-06-03T08:49:25.927880Z",
     "shell.execute_reply": "2025-06-03T08:49:25.927123Z",
     "shell.execute_reply.started": "2025-06-03T08:49:25.923858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def select_random_sample(dataloader):\n",
    "    idx = random.randint(0, len(dataloader.dataset) - 1)\n",
    "    blur_img, sharp_img = dataloader.dataset[idx]\n",
    "    return blur_img, sharp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:49:25.928789Z",
     "iopub.status.busy": "2025-06-03T08:49:25.928615Z",
     "iopub.status.idle": "2025-06-03T08:49:25.950059Z",
     "shell.execute_reply": "2025-06-03T08:49:25.949274Z",
     "shell.execute_reply.started": "2025-06-03T08:49:25.928775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(models, dataloader, device, model_names):\n",
    "    blur_img, sharp_img = select_random_sample(dataloader)\n",
    "    blur_img_tensor = blur_img.unsqueeze(0).to(device)\n",
    "\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(blur_img_tensor)\n",
    "            pred_np = denorm(output.squeeze(0).cpu()).permute(1, 2, 0).clamp(0, 1).numpy()\n",
    "            predictions.append(pred_np)\n",
    "\n",
    "    blur_np = denorm(blur_img).permute(1, 2, 0).clamp(0, 1).numpy()\n",
    "    sharp_np = denorm(sharp_img).permute(1, 2, 0).clamp(0, 1).numpy()\n",
    "\n",
    "    images = [blur_np, sharp_np] + predictions\n",
    "    titles = [\"Blurred Input\", \"Ground Truth\"] + [f\"{name} Prediction\" for name in model_names]\n",
    "\n",
    "    n_images = len(images)\n",
    "    cols = 4\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n",
    "\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < n_images:\n",
    "            ax.imshow(images[idx])\n",
    "            ax.set_title(titles[idx])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T08:49:25.951204Z",
     "iopub.status.busy": "2025-06-03T08:49:25.950969Z",
     "iopub.status.idle": "2025-06-03T08:49:27.696932Z",
     "shell.execute_reply": "2025-06-03T08:49:27.695833Z",
     "shell.execute_reply.started": "2025-06-03T08:49:25.951186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models = [model_cnn, model_unet, model_resnet, generator_cnn, generator_unet, generator_resnet]\n",
    "model_names = [\"CNN\", \"UNet\", \"ResNet\", \"GAN_CNN\", \"GAN_UNet\", \"GAN_ResNet\"]\n",
    "visualize_predictions(models, val_loader, device, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF PHASE 1\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset setup change for Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:48:45.429114Z",
     "iopub.status.busy": "2025-07-02T06:48:45.428537Z",
     "iopub.status.idle": "2025-07-02T06:48:45.439677Z",
     "shell.execute_reply": "2025-07-02T06:48:45.438925Z",
     "shell.execute_reply.started": "2025-07-02T06:48:45.429077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CropPatchDataset(Dataset):\n",
    "    def __init__(self, image_pairs, patch_size=256):\n",
    "        self.image_pairs = image_pairs\n",
    "        self.patch_size = patch_size\n",
    "        self.n_patches = 9 # 3x3 Grid\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((patch_size, patch_size)), \n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_pairs) * self.n_patches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_idx = idx // self.n_patches\n",
    "        patch_idx = idx % self.n_patches\n",
    "\n",
    "        blur_path, sharp_path = self.image_pairs[img_idx]\n",
    "        blur = Image.open(blur_path).convert(\"RGB\")\n",
    "        sharp = Image.open(sharp_path).convert(\"RGB\")\n",
    "\n",
    "        w, h = blur.size\n",
    "        grid_size = int(self.n_patches ** 0.5)\n",
    "        pw, ph = w // grid_size, h // grid_size\n",
    "\n",
    "        i = patch_idx // grid_size\n",
    "        j = patch_idx % grid_size\n",
    "        left = j * pw\n",
    "        upper = i * ph\n",
    "\n",
    "        blur_crop = blur.crop((left, upper, left + pw, upper + ph))\n",
    "        sharp_crop = sharp.crop((left, upper, left + pw, upper + ph))\n",
    "\n",
    "        return {\n",
    "            \"condition\": self.transform(blur_crop), \n",
    "            \"target\": self.transform(sharp_crop)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:48:45.604145Z",
     "iopub.status.busy": "2025-07-02T06:48:45.603489Z",
     "iopub.status.idle": "2025-07-02T06:48:45.610849Z",
     "shell.execute_reply": "2025-07-02T06:48:45.610077Z",
     "shell.execute_reply.started": "2025-07-02T06:48:45.604117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FullImageDataset(Dataset):\n",
    "    def __init__(self, image_pairs):\n",
    "        self.image_pairs = image_pairs\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        blur_path, sharp_path = self.image_pairs[idx]\n",
    "        blur = Image.open(blur_path).convert(\"RGB\")\n",
    "        sharp = Image.open(sharp_path).convert(\"RGB\")\n",
    "\n",
    "        return {\n",
    "            \"condition\": self.transform(blur),\n",
    "            \"target\": self.transform(sharp)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:48:45.801451Z",
     "iopub.status.busy": "2025-07-02T06:48:45.801158Z",
     "iopub.status.idle": "2025-07-02T06:53:55.538341Z",
     "shell.execute_reply": "2025-07-02T06:53:55.537558Z",
     "shell.execute_reply.started": "2025-07-02T06:48:45.801430Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def to_gray_np(img):\n",
    "    img_np = np.array(img.convert(\"RGB\")) / 255.0\n",
    "    gray = np.dot(img_np[..., :3], [0.299, 0.587, 0.114])\n",
    "    return gray\n",
    "\n",
    "filtered_pairs = []\n",
    "\n",
    "for blur_path, sharp_path in tqdm(image_pairs, desc='Computing SSIM'):\n",
    "    blur_img = Image.open(blur_path)\n",
    "    sharp_img = Image.open(sharp_path)\n",
    "\n",
    "    blur_gray = to_gray_np(blur_img)\n",
    "    sharp_gray = to_gray_np(sharp_img)\n",
    "\n",
    "    ssim_score = ssim(blur_gray, sharp_gray, data_range=1.0)\n",
    "\n",
    "    if ssim_score <= 0.8:\n",
    "        filtered_pairs.append((blur_path, sharp_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:53:55.539718Z",
     "iopub.status.busy": "2025-07-02T06:53:55.539446Z",
     "iopub.status.idle": "2025-07-02T06:53:55.547223Z",
     "shell.execute_reply": "2025-07-02T06:53:55.546465Z",
     "shell.execute_reply.started": "2025-07-02T06:53:55.539701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# === Cropped Patches Image Dataset ===\n",
    "patch_dataset = CropPatchDataset(image_pairs=filtered_pairs)\n",
    "train_size = int(0.8 * len(patch_dataset))\n",
    "val_size = len(patch_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(patch_dataset, [train_size, val_size])\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                         num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                       num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# === Dataset Statistics ===\n",
    "print(f\"Original filtered pairs: {len(filtered_pairs)}\")\n",
    "print(f\"Total patches in dataset: {len(patch_dataset)}\")\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:53:59.613989Z",
     "iopub.status.busy": "2025-07-02T06:53:59.613702Z",
     "iopub.status.idle": "2025-07-02T06:53:59.618575Z",
     "shell.execute_reply": "2025-07-02T06:53:59.617855Z",
     "shell.execute_reply.started": "2025-07-02T06:53:59.613968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alpha_bar = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi / 2) ** 2\n",
    "    alpha_bar = alpha_bar / alpha_bar[0]\n",
    "    betas = 1 - (alpha_bar[1:] / alpha_bar[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:53:59.803864Z",
     "iopub.status.busy": "2025-07-02T06:53:59.803361Z",
     "iopub.status.idle": "2025-07-02T06:54:00.117748Z",
     "shell.execute_reply": "2025-07-02T06:54:00.117141Z",
     "shell.execute_reply.started": "2025-07-02T06:53:59.803829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "timesteps = 1000\n",
    "\n",
    "betas = cosine_beta_schedule(timesteps).to(device)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "alphas_cumprod_prev = torch.cat([torch.tensor([1.], device=device), alphas_cumprod[:-1]])\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - alphas_cumprod)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:00.202039Z",
     "iopub.status.busy": "2025-07-02T06:54:00.201317Z",
     "iopub.status.idle": "2025-07-02T06:54:00.206146Z",
     "shell.execute_reply": "2025-07-02T06:54:00.205290Z",
     "shell.execute_reply.started": "2025-07-02T06:54:00.202012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def q_sample(x_start, t, noise, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod):\n",
    "    sqrt_alpha_bar = sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "    sqrt_one_minus_alpha_bar = sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
    "    return sqrt_alpha_bar * x_start + sqrt_one_minus_alpha_bar * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:00.403259Z",
     "iopub.status.busy": "2025-07-02T06:54:00.402719Z",
     "iopub.status.idle": "2025-07-02T06:54:00.408178Z",
     "shell.execute_reply": "2025-07-02T06:54:00.407401Z",
     "shell.execute_reply.started": "2025-07-02T06:54:00.403237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, device=timesteps.device) * -emb)\n",
    "    emb = timesteps[:, None].float() * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    return emb  # [B, embedding_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion UNet (Conditional UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T10:05:16.394659Z",
     "iopub.status.busy": "2025-06-22T10:05:16.394371Z",
     "iopub.status.idle": "2025-06-22T10:05:16.400604Z",
     "shell.execute_reply": "2025-06-22T10:05:16.399845Z",
     "shell.execute_reply.started": "2025-06-22T10:05:16.394642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim, use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_emb_dim, out_channels)\n",
    "        )\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if use_dropout:\n",
    "            layers.insert(3, nn.Dropout(0.2))\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        \"\"\"\n",
    "        x: feature map [B, C, H, W]\n",
    "        t_emb: timestep embedding [B, time_emb_dim]\n",
    "        \"\"\"\n",
    "        h = self.conv(x)\n",
    "        # Add timestep embedding: reshape and broadcast\n",
    "        t = self.time_mlp(t_emb)\n",
    "        return h + t[:, :, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T10:05:16.569908Z",
     "iopub.status.busy": "2025-06-22T10:05:16.569204Z",
     "iopub.status.idle": "2025-06-22T10:05:16.573986Z",
     "shell.execute_reply": "2025-06-22T10:05:16.573361Z",
     "shell.execute_reply.started": "2025-06-22T10:05:16.569886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim, use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv = ConvBlock(in_channels, out_channels, time_emb_dim, use_dropout)\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        x = self.pool(x)\n",
    "        return self.conv(x, t_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T10:05:16.752450Z",
     "iopub.status.busy": "2025-06-22T10:05:16.752202Z",
     "iopub.status.idle": "2025-06-22T10:05:16.757996Z",
     "shell.execute_reply": "2025-06-22T10:05:16.757194Z",
     "shell.execute_reply.started": "2025-06-22T10:05:16.752435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim, use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv = ConvBlock(in_channels, out_channels, time_emb_dim, use_dropout)\n",
    "\n",
    "    def forward(self, x1, x2, t_emb):\n",
    "        x1 = self.upconv(x1)\n",
    "        if x1.size() != x2.size():\n",
    "            x1 = F.interpolate(x1, size=x2.size()[2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x, t_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T10:05:16.943910Z",
     "iopub.status.busy": "2025-06-22T10:05:16.943091Z",
     "iopub.status.idle": "2025-06-22T10:05:16.952100Z",
     "shell.execute_reply": "2025-06-22T10:05:16.951214Z",
     "shell.execute_reply.started": "2025-06-22T10:05:16.943871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConditionalUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, condition_channels=3, out_channels=3, time_emb_dim, use_dropout=False):\n",
    "        \"\"\"\n",
    "        in_channels: channels of noisy image\n",
    "        condition_channels: channels of blurry image\n",
    "        out_channels: output channels (predicting noise)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim)\n",
    "        )\n",
    "\n",
    "        total_in_channels = in_channels + condition_channels\n",
    "\n",
    "        self.in_conv = ConvBlock(total_in_channels, 64, time_emb_dim, use_dropout)\n",
    "\n",
    "        self.enc1 = Encoder(64, 128, time_emb_dim, use_dropout)\n",
    "        self.enc2 = Encoder(128, 256, time_emb_dim, use_dropout)\n",
    "        self.enc3 = Encoder(256, 512, time_emb_dim, use_dropout)\n",
    "        self.enc4 = Encoder(512, 1024, time_emb_dim, use_dropout)\n",
    "\n",
    "        self.dec1 = Decoder(1024, 512, time_emb_dim, use_dropout)\n",
    "        self.dec2 = Decoder(512, 256, time_emb_dim, use_dropout)\n",
    "        self.dec3 = Decoder(256, 128, time_emb_dim, use_dropout)\n",
    "        self.dec4 = Decoder(128, 64, time_emb_dim, use_dropout)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x_noisy, t, condition):\n",
    "        \"\"\"\n",
    "        x_noisy: [B, in_channels, H, W]\n",
    "        t: [B] integer timesteps\n",
    "        condition: [B, condition_channels, H, W] (blurred input)\n",
    "        \"\"\"\n",
    "        x = torch.cat([x_noisy, condition], dim=1)\n",
    "\n",
    "        t_emb = get_timestep_embedding(t, self.time_mlp[0].in_features)\n",
    "        t_emb = self.time_mlp(t_emb)\n",
    "\n",
    "        # Pass through UNet with timestep embedding\n",
    "        x1 = self.in_conv(x, t_emb)\n",
    "        x2 = self.enc1(x1, t_emb)\n",
    "        x3 = self.enc2(x2, t_emb)\n",
    "        x4 = self.enc3(x3, t_emb)\n",
    "        x5 = self.enc4(x4, t_emb)\n",
    "\n",
    "        x = self.dec1(x5, x4, t_emb)\n",
    "        x = self.dec2(x, x3, t_emb)\n",
    "        x = self.dec3(x, x2, t_emb)\n",
    "        x = self.dec4(x, x1, t_emb)\n",
    "\n",
    "        return self.out_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:06.543898Z",
     "iopub.status.busy": "2025-07-02T06:54:06.543386Z",
     "iopub.status.idle": "2025-07-02T06:54:06.550670Z",
     "shell.execute_reply": "2025-07-02T06:54:06.549920Z",
     "shell.execute_reply.started": "2025-07-02T06:54:06.543861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim, use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_channels)\n",
    "\n",
    "        self.norm1 = nn.GroupNorm(min(8, in_channels), in_channels)\n",
    "        self.norm2 = nn.GroupNorm(min(8, out_channels), out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2) if use_dropout else nn.Identity()\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "      # First norm + activation + conv\n",
    "      h = self.norm1(x)\n",
    "      h = self.relu(h)\n",
    "      h = self.conv1(h)\n",
    "\n",
    "      # Second norm + activation + dropout + conv\n",
    "      h = self.norm2(h)\n",
    "      h = self.relu(h)\n",
    "      h = self.dropout(h)\n",
    "      h = self.conv2(h)\n",
    "\n",
    "      # Add timestep embedding\n",
    "      t = self.time_mlp(t_emb)\n",
    "      h = h + t[:, :, None, None]\n",
    "\n",
    "      # Residual connection\n",
    "      return h + self.shortcut(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:06.701077Z",
     "iopub.status.busy": "2025-07-02T06:54:06.700810Z",
     "iopub.status.idle": "2025-07-02T06:54:06.707766Z",
     "shell.execute_reply": "2025-07-02T06:54:06.706961Z",
     "shell.execute_reply.started": "2025-07-02T06:54:06.701060Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.key = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.value = nn.Conv2d(in_channels, in_channels // 8, 1)  # Fixed to match query/key\n",
    "        self.proj_out = nn.Conv2d(in_channels // 8, in_channels, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        query = self.query(x).view(B, -1, H * W).permute(0, 2, 1)  # B x HW x C//8\n",
    "        key = self.key(x).view(B, -1, H * W)  # B x C//8 x HW\n",
    "        value = self.value(x).view(B, -1, H * W)  # B x C//8 x HW\n",
    "\n",
    "        attn = torch.bmm(query, key)  # B x HW x HW\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "        out = torch.bmm(value, attn.permute(0, 2, 1))  # B x C//8 x HW\n",
    "        out = out.view(B, C // 8, H, W)\n",
    "        out = self.proj_out(out)\n",
    "        out = self.gamma * out + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:06.845631Z",
     "iopub.status.busy": "2025-07-02T06:54:06.845063Z",
     "iopub.status.idle": "2025-07-02T06:54:06.849956Z",
     "shell.execute_reply": "2025-07-02T06:54:06.849244Z",
     "shell.execute_reply.started": "2025-07-02T06:54:06.845607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim, use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.block = ResidualBlock(in_channels, out_channels, time_emb_dim, use_dropout)\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        x = self.pool(x)\n",
    "        return self.block(x, t_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:07.007360Z",
     "iopub.status.busy": "2025-07-02T06:54:07.007084Z",
     "iopub.status.idle": "2025-07-02T06:54:07.012777Z",
     "shell.execute_reply": "2025-07-02T06:54:07.011983Z",
     "shell.execute_reply.started": "2025-07-02T06:54:07.007339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim, use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.block = ResidualBlock(in_channels, out_channels, time_emb_dim, use_dropout)\n",
    "\n",
    "    def forward(self, x1, x2, t_emb):\n",
    "        x1 = self.upconv(x1)\n",
    "        if x1.size() != x2.size():\n",
    "            x1 = F.interpolate(x1, size=x2.size()[2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.block(x, t_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:07.129895Z",
     "iopub.status.busy": "2025-07-02T06:54:07.129349Z",
     "iopub.status.idle": "2025-07-02T06:54:07.140379Z",
     "shell.execute_reply": "2025-07-02T06:54:07.139766Z",
     "shell.execute_reply.started": "2025-07-02T06:54:07.129872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConditionalUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, condition_channels=3, out_channels=3, \n",
    "                 time_emb_dim=256, use_dropout=False):\n",
    "        \"\"\"\n",
    "        in_channels: channels of noisy image\n",
    "        condition_channels: channels of blurry image\n",
    "        out_channels: output channels (predicting noise)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.time_emb_dim = time_emb_dim\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim)\n",
    "        )\n",
    "\n",
    "        total_in_channels = in_channels + condition_channels\n",
    "\n",
    "        self.in_conv = ResidualBlock(total_in_channels, 64, time_emb_dim, use_dropout)\n",
    "\n",
    "        self.enc1 = Encoder(64, 128, time_emb_dim, use_dropout)\n",
    "        self.enc2 = Encoder(128, 256, time_emb_dim, use_dropout)\n",
    "        #self.attn_enc2 = SelfAttention(256) # Add attnetion at Enc2\n",
    "        self.enc3 = Encoder(256, 512, time_emb_dim, use_dropout)\n",
    "        self.attn_enc3 = SelfAttention(512) # # Add attnetion at Enc3\n",
    "        self.enc4 = Encoder(512, 1024, time_emb_dim, use_dropout)\n",
    "        self.attn_bottleneck = SelfAttention(1024) # Add attnetion at BottleNeck\n",
    "      \n",
    "        self.dec1 = Decoder(1024, 512, time_emb_dim, use_dropout)\n",
    "        self.dec2 = Decoder(512, 256, time_emb_dim, use_dropout)\n",
    "        self.attn_dec2 = SelfAttention(256) # Add attnetion at Dec2\n",
    "        self.dec3 = Decoder(256, 128, time_emb_dim, use_dropout)\n",
    "        self.attn_dec3 = SelfAttention(128) # Add attnetion at Dec3\n",
    "        self.dec4 = Decoder(128, 64, time_emb_dim, use_dropout)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x_noisy, t, condition):\n",
    "        \"\"\"\n",
    "        x_noisy: [B, in_channels, H, W]\n",
    "        t: [B] integer timesteps\n",
    "        condition: [B, condition_channels, H, W] (blurred input)\n",
    "        \"\"\"\n",
    "        if condition is None:\n",
    "            condition = torch.zeros_like(x_noisy) # Neutral placeholder\n",
    "            \n",
    "        x = torch.cat([x_noisy, condition], dim=1)\n",
    "\n",
    "        t_emb = get_timestep_embedding(t, self.time_emb_dim)\n",
    "        t_emb = self.time_mlp(t_emb)\n",
    "        \n",
    "        # Pass through UNet with timestep embedding\n",
    "        x1 = self.in_conv(x, t_emb)\n",
    "        x2 = self.enc1(x1, t_emb)\n",
    "        x3 = self.enc2(x2, t_emb)\n",
    "        #x3 = self.attn_enc2(x3) # Apply attention at Enc2\n",
    "        x4 = self.enc3(x3, t_emb)\n",
    "        x4 = self.attn_enc3(x4) # Apply attention at Enc3\n",
    "        x5 = self.enc4(x4, t_emb)\n",
    "        x5 = self.attn_bottleneck(x5) # Apply attention at BottleNeck\n",
    "      \n",
    "        x = self.dec1(x5, x4, t_emb)\n",
    "        x = self.dec2(x, x3, t_emb)\n",
    "        x = self.attn_dec2(x) # Apply attention at Dec2\n",
    "        x = self.dec3(x, x2, t_emb)\n",
    "        x = self.attn_dec3(x) # Apply attention at Dec3\n",
    "        x = self.dec4(x, x1, t_emb)\n",
    "\n",
    "        return self.out_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:07.301670Z",
     "iopub.status.busy": "2025-07-02T06:54:07.301055Z",
     "iopub.status.idle": "2025-07-02T06:54:07.307675Z",
     "shell.execute_reply": "2025-07-02T06:54:07.306776Z",
     "shell.execute_reply.started": "2025-07-02T06:54:07.301645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "        self.register()\n",
    "\n",
    "    def register(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data\n",
    "\n",
    "    def apply_shadow(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and name in self.backup:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:07.610109Z",
     "iopub.status.busy": "2025-07-02T06:54:07.609864Z",
     "iopub.status.idle": "2025-07-02T06:54:07.615418Z",
     "shell.execute_reply": "2025-07-02T06:54:07.614555Z",
     "shell.execute_reply.started": "2025-07-02T06:54:07.610093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        vgg = models.vgg16(pretrained=True).features[:16]\n",
    "        for param in vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vgg = vgg.eval().to(device)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        assert input.shape == target.shape, \"Perceptual input/target shape mismatch\"\n",
    "        # input and target: [B, 3, H, W], normalized to [0, 1]\n",
    "        return F.l1_loss(self.vgg(input), self.vgg(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:07.705047Z",
     "iopub.status.busy": "2025-07-02T06:54:07.704727Z",
     "iopub.status.idle": "2025-07-02T06:54:07.710210Z",
     "shell.execute_reply": "2025-07-02T06:54:07.709294Z",
     "shell.execute_reply.started": "2025-07-02T06:54:07.705025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_for_vgg(tensor):\n",
    "    # Convert from [-1, 1] to [0, 1]\n",
    "    tensor = (tensor + 1) * 0.5\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "    # Apply ImageNet normalization\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=tensor.device).view(1, 3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225], device=tensor.device).view(1, 3, 1, 1)\n",
    "    return (tensor - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:09.402231Z",
     "iopub.status.busy": "2025-07-02T06:54:09.401232Z",
     "iopub.status.idle": "2025-07-02T06:54:13.707063Z",
     "shell.execute_reply": "2025-07-02T06:54:13.706469Z",
     "shell.execute_reply.started": "2025-07-02T06:54:09.402205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "percep_loss_fn = PerceptualLoss()\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "l1_loss_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Diffusion Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:16.604134Z",
     "iopub.status.busy": "2025-07-02T06:54:16.603842Z",
     "iopub.status.idle": "2025-07-02T06:54:16.614170Z",
     "shell.execute_reply": "2025-07-02T06:54:16.613434Z",
     "shell.execute_reply.started": "2025-07-02T06:54:16.604114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_diff(model, train_loader, optimizer, scheduler, scheduler_params,\n",
    "              device, epochs, log_interval=10):\n",
    "    model.to(device)\n",
    "    betas = scheduler_params['betas']\n",
    "    sqrt_alphas_cumprod = scheduler_params['sqrt_alphas_cumprod']\n",
    "    sqrt_one_minus_alphas_cumprod = scheduler_params['sqrt_one_minus_alphas_cumprod']\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    T = len(scheduler_params['betas'])\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch [{epoch}/{epochs}]\", leave=False)\n",
    "        for step, batch in enumerate(loop, 1):\n",
    "            with autocast():\n",
    "                x_blur = batch['condition'].to(device)\n",
    "                x_sharp = batch['target'].to(device)\n",
    "    \n",
    "                B = x_sharp.size(0)\n",
    "                t = torch.randint(0, len(betas), (B,), device=device)\n",
    "                noise = torch.randn_like(x_sharp)\n",
    "                x_t = q_sample(x_sharp, t, noise, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod)\n",
    "    \n",
    "                pred_noise = model(x_t, t, x_blur)\n",
    "                \n",
    "                mse_loss = mse_loss_fn(pred_noise, noise)\n",
    "    \n",
    "                # Recover x0\n",
    "                alpha_cumprod_t = sqrt_alphas_cumprod[t] ** 2\n",
    "                alpha_cumprod_t = alpha_cumprod_t.view(-1, 1, 1, 1)\n",
    "                eps = 1e-8\n",
    "                x0_pred = (x_t - torch.sqrt(1 - alpha_cumprod_t + eps) * pred_noise) / torch.sqrt(alpha_cumprod_t)\n",
    "                x0_pred = x0_pred.clamp(-1.0, 1.0)\n",
    "                \n",
    "                # Preprocess for perceptual\n",
    "                x0_pred_vgg = preprocess_for_vgg(x0_pred)\n",
    "                x_sharp_vgg = preprocess_for_vgg(x_sharp)\n",
    "        \n",
    "                # Perceptual and L1 Loss\n",
    "                percep = percep_loss_fn(x0_pred_vgg, x_sharp_vgg)\n",
    "                l1 = l1_loss_fn(x0_pred, x_sharp)\n",
    "    \n",
    "                # Total Loss\n",
    "                loss = mse_loss + 0.4 * l1 + 0.3 * percep\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                ema.update()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "    \n",
    "                if step % log_interval == 0:\n",
    "                    loop.set_postfix(loss=loss.item())\n",
    "                    \n",
    "        scheduler.step()\n",
    "        with torch.no_grad():\n",
    "            t_log = torch.randint(0, T, (B,), device=device).long()\n",
    "            noise = torch.randn_like(x_sharp)\n",
    "            x_t_log = q_sample(x_sharp, t_log, noise, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod)\n",
    "            pred_noise_log = model(x_t_log, t_log, x_blur)\n",
    "            print(f\"[Step {step}] pred_noise mean/std: {pred_noise_log.mean().item():.4f} / {pred_noise_log.std().item():.4f}\")\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch}/{epochs}] - Avg Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:16.802077Z",
     "iopub.status.busy": "2025-07-02T06:54:16.801351Z",
     "iopub.status.idle": "2025-07-02T06:54:18.502163Z",
     "shell.execute_reply": "2025-07-02T06:54:18.501474Z",
     "shell.execute_reply.started": "2025-07-02T06:54:16.802053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total Parameters: {total_params:,}\")\n",
    "    print(f\"Trainable Parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-29T07:54:28.929360Z",
     "iopub.status.busy": "2025-06-29T07:54:28.929088Z",
     "iopub.status.idle": "2025-06-29T18:11:25.477642Z",
     "shell.execute_reply": "2025-06-29T18:11:25.476491Z",
     "shell.execute_reply.started": "2025-06-29T07:54:28.929341Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_diffunet = ConditionalUNet(in_channels=3, condition_channels=3, out_channels=3, time_emb_dim=256).to(device)\n",
    "ema = EMA(model_diffunet)\n",
    "optimizer = torch.optim.AdamW(model_diffunet.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "scheduler_params = {'betas': betas, 'sqrt_alphas_cumprod': sqrt_alphas_cumprod, \n",
    "                    'sqrt_one_minus_alphas_cumprod': sqrt_one_minus_alphas_cumprod,}\n",
    "\n",
    "count_parameters(model_diffunet)\n",
    "\n",
    "print(\"\\n[Phase 1] Training on patch dataset...\")\n",
    "train_diff(model=model_diffunet, train_loader=train_loader, optimizer=optimizer, \n",
    "           scheduler=scheduler, scheduler_params=scheduler_params, device=device, \n",
    "           epochs=20, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T18:11:33.114801Z",
     "iopub.status.busy": "2025-06-29T18:11:33.114194Z",
     "iopub.status.idle": "2025-06-29T18:11:34.071798Z",
     "shell.execute_reply": "2025-06-29T18:11:34.071156Z",
     "shell.execute_reply.started": "2025-06-29T18:11:33.114773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state\": model_diffunet.state_dict(), \n",
    "    \"optimizer_state\": optimizer.state_dict(), \n",
    "    \"scheduler_state\": scheduler.state_dict(), \n",
    "    \"ema_shadow\": ema.shadow,\n",
    "}, \"phase1_checkpoint.pth\")\n",
    "print(\"Checkpoint saved to 'phase1_checkpoint.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:22.812988Z",
     "iopub.status.busy": "2025-07-02T06:54:22.812295Z",
     "iopub.status.idle": "2025-07-02T07:10:07.134269Z",
     "shell.execute_reply": "2025-07-02T07:10:07.133062Z",
     "shell.execute_reply.started": "2025-07-02T06:54:22.812967Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_diffunet = ConditionalUNet(in_channels=3, condition_channels=3, out_channels=3, time_emb_dim=256).to(device)\n",
    "ema = EMA(model_diffunet)\n",
    "optimizer = torch.optim.AdamW(model_diffunet.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "scheduler_params = {'betas': betas, 'sqrt_alphas_cumprod': sqrt_alphas_cumprod, \n",
    "                    'sqrt_one_minus_alphas_cumprod': sqrt_one_minus_alphas_cumprod,}\n",
    "\n",
    "count_parameters(model_diffunet)\n",
    "\n",
    "checkpoint = torch.load(\"/kaggle/input/deblurring-image/pytorch/default/3/phase1_checkpoint.pth\")\n",
    "\n",
    "model_diffunet.load_state_dict(checkpoint[\"model_state\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n",
    "ema.shadow = checkpoint[\"ema_shadow\"]\n",
    "\n",
    "# Clean up before switching\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# === Full Image Dataset ===\n",
    "full_image_dataset = FullImageDataset(filtered_pairs)\n",
    "train_loader = DataLoader(full_image_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                         num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"\\n[Phase 2] Fine-tuning on full image dataset...\")\n",
    "train_diff(model=model_diffunet, train_loader=train_loader, optimizer=optimizer, \n",
    "           scheduler=scheduler, scheduler_params=scheduler_params, device=device, \n",
    "           epochs=15, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T07:10:29.479416Z",
     "iopub.status.busy": "2025-07-02T07:10:29.478994Z",
     "iopub.status.idle": "2025-07-02T07:10:30.519711Z",
     "shell.execute_reply": "2025-07-02T07:10:30.519058Z",
     "shell.execute_reply.started": "2025-07-02T07:10:29.479391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state\": model_diffunet.state_dict(), \n",
    "    \"optimizer_state\": optimizer.state_dict(), \n",
    "    \"scheduler_state\": scheduler.state_dict(), \n",
    "    \"ema_shadow\": ema.shadow,\n",
    "}, \"phase1_checkpoint.pth\")\n",
    "print(\"Checkpoint saved to 'phase2_checkpoint.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T07:10:33.056054Z",
     "iopub.status.busy": "2025-07-02T07:10:33.055484Z",
     "iopub.status.idle": "2025-07-02T07:10:33.062662Z",
     "shell.execute_reply": "2025-07-02T07:10:33.061901Z",
     "shell.execute_reply.started": "2025-07-02T07:10:33.056032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_ddpm(model, condition, scheduler_params, device, num_steps):\n",
    "    betas = scheduler_params['betas']\n",
    "    alphas = 1.0 - betas\n",
    "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "    alphas_cumprod_prev = torch.cat([torch.tensor([1.], device=device), alphas_cumprod[:-1]])\n",
    "\n",
    "    eps = 1e-5\n",
    "    sqrt_recip_alphas = torch.sqrt(1.0 / torch.clamp(alphas, min=eps))\n",
    "    posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "    posterior_variance = torch.clamp(posterior_variance, min=eps)\n",
    "\n",
    "    B, C, H, W = condition.shape\n",
    "    x_t = torch.randn((B, C, H, W), device=device)\n",
    "\n",
    "    for t in reversed(range(num_steps)):\n",
    "        t_batch = torch.full((B,), t, device=device, dtype=torch.long)\n",
    "\n",
    "        pred_noise = model(x_t, t_batch, condition)\n",
    "\n",
    "        rec_alpha = sqrt_recip_alphas[t]\n",
    "        beta_t = betas[t]\n",
    "        acp_t = alphas_cumprod[t]\n",
    "\n",
    "        mean = rec_alpha * (x_t - (beta_t / torch.sqrt(1.0 - acp_t)) * pred_noise)\n",
    "\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(x_t)\n",
    "            sigma = torch.sqrt(posterior_variance[t])\n",
    "            x_t = mean + sigma * noise\n",
    "        else:\n",
    "            x_t = mean\n",
    "\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T07:10:33.206970Z",
     "iopub.status.busy": "2025-07-02T07:10:33.206673Z",
     "iopub.status.idle": "2025-07-02T07:10:33.214874Z",
     "shell.execute_reply": "2025-07-02T07:10:33.214034Z",
     "shell.execute_reply.started": "2025-07-02T07:10:33.206949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_ddim(model, condition, scheduler_params, device, num_steps, eta):\n",
    "    betas = scheduler_params['betas']\n",
    "    alphas = 1.0 - betas\n",
    "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "    T = len(betas)\n",
    "    ddim_timesteps = torch.linspace(T - 1, 0, steps=num_steps, dtype=torch.float64).round().long().to(device)\n",
    "\n",
    "    B, C, H, W = condition.shape\n",
    "    x_t = torch.randn((B, C, H, W), device=device)\n",
    "\n",
    "    for i in range(len(ddim_timesteps)):\n",
    "        t = ddim_timesteps[i]\n",
    "        t_batch = torch.full((B,), t, device=device, dtype=torch.long)\n",
    "\n",
    "        pred_noise = model(x_t, t_batch, condition)\n",
    "        alpha_cumprod_t = alphas_cumprod[t]\n",
    "\n",
    "        x0_pred = (x_t - torch.sqrt(1 - alpha_cumprod_t) * pred_noise) / torch.sqrt(alpha_cumprod_t)\n",
    "        x0_pred = x0_pred.clamp(-1.0, 1.0)\n",
    "        \n",
    "        if i == len(ddim_timesteps) - 1:\n",
    "            x_t = x0_pred\n",
    "        else:\n",
    "            t_next = ddim_timesteps[i + 1]\n",
    "            alpha_cumprod_next = alphas_cumprod[t_next]\n",
    "\n",
    "            sigma = (\n",
    "                eta * torch.sqrt(\n",
    "                    (1 - alpha_cumprod_next) / (1 - alpha_cumprod_t)\n",
    "                )\n",
    "                * torch.sqrt(1 - alpha_cumprod_t / alpha_cumprod_next)\n",
    "            ).clamp(min=0)\n",
    "\n",
    "            noise = torch.randn_like(x_t) if eta > 0 else 0.0\n",
    "\n",
    "            eps = 1e-5\n",
    "            sqrt_term = torch.sqrt(torch.clamp(1 - alpha_cumprod_next - sigma ** 2, min=eps))\n",
    "\n",
    "            x_t = (\n",
    "                torch.sqrt(alpha_cumprod_next) * x0_pred\n",
    "                + sqrt_term * pred_noise\n",
    "                + sigma * noise\n",
    "            )\n",
    "\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T07:10:50.162824Z",
     "iopub.status.busy": "2025-07-02T07:10:50.162534Z",
     "iopub.status.idle": "2025-07-02T07:10:50.167329Z",
     "shell.execute_reply": "2025-07-02T07:10:50.166387Z",
     "shell.execute_reply.started": "2025-07-02T07:10:50.162807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def denorm(t):\n",
    "    return (t.clamp(-1, 1) + 1) / 2\n",
    "\n",
    "val_loader_full = DataLoader(FullImageDataset(filtered_pairs), batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T07:10:50.333470Z",
     "iopub.status.busy": "2025-07-02T07:10:50.333201Z",
     "iopub.status.idle": "2025-07-02T07:10:50.341900Z",
     "shell.execute_reply": "2025-07-02T07:10:50.341002Z",
     "shell.execute_reply.started": "2025-07-02T07:10:50.333451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def model_evaluation(model, val_loader, scheduler_params, device, num_steps, \n",
    "                     eta, model_name=\"Model\"):\n",
    "    model.eval()\n",
    "    psnr_list, ssim_list, lpips_list = [], [], []\n",
    "\n",
    "    lpips_module = LPIPS(net_type='alex').to(device)\n",
    "    fid_module = FID(feature=2048).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Evaluating {model_name}\"):\n",
    "            x_blur = batch['condition'].to(device)\n",
    "            x_sharp = batch['target'].to(device)\n",
    "\n",
    "            # Generate deblurred output\n",
    "            x_fake = sample_ddim(model, x_blur, scheduler_params, device, num_steps, eta)\n",
    "\n",
    "            # Add predictions and GT to FID module\n",
    "            fid_module.update(denorm(x_fake).mul(255).byte(), real=False)\n",
    "            fid_module.update(denorm(x_sharp).mul(255).byte(), real=True)\n",
    "\n",
    "            for b in range(x_blur.size(0)):\n",
    "                pred = denorm(x_fake[b].unsqueeze(0))\n",
    "                target = denorm(x_sharp[b].unsqueeze(0))\n",
    "\n",
    "                psnr_value = psnr_fn(pred, target, data_range=1.0).item()\n",
    "                ssim_value = ssim_fn(pred, target, data_range=1.0).item()\n",
    "                lpips_value = lpips_module(pred, target).item()\n",
    "\n",
    "                psnr_list.append(psnr_value)\n",
    "                ssim_list.append(ssim_value)\n",
    "                lpips_list.append(lpips_value)\n",
    "\n",
    "    psnr_avg = np.mean(psnr_list)\n",
    "    ssim_avg = np.mean(ssim_list)\n",
    "    lpips_avg = np.mean(lpips_list)\n",
    "    fid_value = fid_module.compute().item()\n",
    "\n",
    "    print(f\"{'Model':<15}{'PSNR (dB)':>12}{'SSIM':>12}{'LPIPS':>12}{'FID':>12}\")\n",
    "    print(\"-\" * 63)\n",
    "    print(f\"{model_name:<15}{psnr_avg:>12.2f}{ssim_avg:>12.4f}{lpips_avg:>12.4f}{fid_value:>12.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"PSNR\": psnr_avg,\n",
    "        \"SSIM\": ssim_avg,\n",
    "        \"LPIPS\": lpips_avg,\n",
    "        \"FID\": fid_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T07:10:50.534036Z",
     "iopub.status.busy": "2025-07-02T07:10:50.533779Z",
     "iopub.status.idle": "2025-07-02T07:13:53.915819Z",
     "shell.execute_reply": "2025-07-02T07:13:53.914917Z",
     "shell.execute_reply.started": "2025-07-02T07:10:50.534019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ema.apply_shadow()\n",
    "\n",
    "metrics_unet = model_evaluation(\n",
    "    model=model_diffunet,\n",
    "    val_loader=val_loader_full ,\n",
    "    scheduler_params=scheduler_params,\n",
    "    device=device,\n",
    "    num_steps=10, \n",
    "    eta=0.3, \n",
    "    model_name=\"UNet Diffusion\"\n",
    ")\n",
    "\n",
    "ema.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T07:13:58.103103Z",
     "iopub.status.busy": "2025-07-02T07:13:58.102807Z",
     "iopub.status.idle": "2025-07-02T07:13:58.111210Z",
     "shell.execute_reply": "2025-07-02T07:13:58.110423Z",
     "shell.execute_reply.started": "2025-07-02T07:13:58.103081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_diffusion(model, val_loader, scheduler_params, device, num_steps, eta, batch):\n",
    "    model.eval()\n",
    "    #batch = next(iter(val_loader))\n",
    "    x_blur = batch['condition'].to(device)\n",
    "    x_sharp = batch['target'].to(device)\n",
    "\n",
    "    # Generate deblurred output\n",
    "    with torch.no_grad():\n",
    "        x_fake = sample_ddim(model, x_blur, scheduler_params, device, num_steps, eta)\n",
    "\n",
    "    # Denormalize to [0, 1]\n",
    "    blur_vis = denorm(x_blur).cpu()\n",
    "    fake_vis = denorm(x_fake).cpu()\n",
    "    sharp_vis = denorm(x_sharp).cpu()\n",
    "\n",
    "    B = blur_vis.size(0)\n",
    "\n",
    "    # Visualize first few examples in batch\n",
    "    n_show = min(B, 4)\n",
    "\n",
    "    fig, axs = plt.subplots(n_show, 3, figsize=(12, 4 * n_show))\n",
    "\n",
    "    if n_show == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for i in range(n_show):\n",
    "        blur_img = np.transpose(blur_vis[i].numpy(), (1, 2, 0))\n",
    "        fake_img = np.transpose(fake_vis[i].numpy(), (1, 2, 0))\n",
    "        sharp_img = np.transpose(sharp_vis[i].numpy(), (1, 2, 0))\n",
    "\n",
    "        axs[i][0].imshow(blur_img)\n",
    "        axs[i][0].set_title(f\"Blurry Input [{i}]\")\n",
    "        axs[i][0].axis(\"off\")\n",
    "\n",
    "        axs[i][1].imshow(fake_img)\n",
    "        axs[i][1].set_title(f\"Deblurred Output [{i}]\")\n",
    "        axs[i][1].axis(\"off\")\n",
    "\n",
    "        axs[i][2].imshow(sharp_img)\n",
    "        axs[i][2].set_title(f\"Ground Truth [{i}]\")\n",
    "        axs[i][2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T07:13:58.277337Z",
     "iopub.status.busy": "2025-07-02T07:13:58.276589Z",
     "iopub.status.idle": "2025-07-02T07:14:00.165598Z",
     "shell.execute_reply": "2025-07-02T07:14:00.164492Z",
     "shell.execute_reply.started": "2025-07-02T07:13:58.277312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ema.apply_shadow()\n",
    "\n",
    "val_iter = iter(val_loader)\n",
    "batch1 = next(val_iter)\n",
    "visualize_diffusion(\n",
    "    model=model_diffunet, \n",
    "    val_loader=val_loader_full,\n",
    "    scheduler_params=scheduler_params,\n",
    "    device=device,\n",
    "    num_steps=10, \n",
    "    eta=0.3, \n",
    "    batch=batch1\n",
    ")\n",
    "\n",
    "ema.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 627736,
     "sourceId": 1118216,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2440998,
     "sourceId": 4131539,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 366034,
     "modelInstanceId": 344738,
     "sourceId": 423042,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 382596,
     "modelInstanceId": 361608,
     "sourceId": 447618,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
